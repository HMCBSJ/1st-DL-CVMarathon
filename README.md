# 1st-DL-CVMarathon

(第五屆機器學習馬拉松)

#### 參加目的：持續練習，熟練語法與套件，訓練資料視覺化、DataFrame...等pandas技能，基本的機器學習、深度學習與kaggle練習

D1：資料介紹與評估資料

D2：機器學習概論

D3：機器學習 - 流程與步驟

D4：EDA/讀取資料與分析流程

D5：如何新建一個 dataframe? 如何讀取其他資料? (非 csv 的資料)

D6：EDA：欄位的資料類型介紹及處理

D7：特徵類型

D8：EDA資料分佈

D9：EDA: Outlier 及處理

D10：數值型特徵 - 去除離群值

D11：常用的數值取代：中位數與分位數連續數值標準化

D12：數值型特徵-補缺失值與標準化

D13：DataFrame operationData frame merge/常用的 DataFrame 操作

D14：程式實作 EDA: correlation/相關係數簡介

D15：EDA from Correlation

D16：EDA: 不同數值範圍間的特徵如何檢視/繪圖與樣式Kernel Density Estimation (KDE)

D17：EDA: 把連續型變數離散化

D18：程式實作 把連續型變數離散化

D19：Subplots

D20：Heatmap & Grid-plot

D21：模型初體驗 Logistic Regression

D22：特徵工程簡介

D23：數值型特徵 - 去除偏態

D24：類別型特徵 - 基礎處理

D25：類別型特徵 - 均值編碼

D26：類別型特徵 - 其他進階處理

D27：時間型特徵

D28：特徵組合 - 數值與數值組合

D29：特徵組合 - 類別與數值組合

D30：特徵選擇

D31：特徵評估

D32：分類型特徵優化 - 葉編碼

D33：機器如何學習?

D34：訓練/測試集切分的概念

D35：regression vs. classification

D36：評估指標選定/evaluation metrics

D37：regression model 介紹 - 線性迴歸/羅吉斯回歸

D38：regression model 程式碼撰寫

D39：regression model 介紹 - LASSO 回歸/ Ridge 回歸

D40：regression model 程式碼撰寫

D41：tree based model - 決策樹 (Decision Tree) 模型介紹

D42：tree based model - 決策樹程式碼撰寫

D43：tree based model - 隨機森林 (Random Forest) 介紹

D44：tree based model - 隨機森林程式碼撰寫

D45：tree based model - 梯度提升機 (Gradient Boosting Machine) 介紹
(作業為文章閱讀)

D46：梯度提升機 - 程式碼撰寫 Coding 練習日

D47：超參數調整與優化

D48：Kaggle 競賽平台介紹

D49：集成方法 : 混合泛化(Blending)

D50：集成方法 : 堆疊泛化(Stacking)

D51~D53：Kaggle 第一次期中考

D54：clustering 1 非監督式機器學習簡介

D55：clustering 2 聚類算法

D56：K-mean 觀察 : 使用輪廓分析

D57：clustering 3 階層分群算法

D58：階層分群法 觀察 : 使用 2D 樣版資料集

D59：dimension reduction 1 降維方法-主成份分析

D60：PCA 觀察 : 使用手寫辨識資料集

D61：dimension reduction 2 降維方法-T-SNE

D62：t-sne 觀察 : 分群與流形還原

D63：深度學習簡介

D64：深度學習體驗 : 模型調整與學習曲線

D65：深度學習體驗 : 啟動函數與正規化

D66：Keras 安裝與介紹

D67：Keras Dataset

D68：Keras Sequential API

D69：Keras Module API

D70：深度神經網路的基礎知識

D71：損失函數

D72：啟動函數

D73：梯度下降Gradient Descent

D74：Gradient Descent 數學原理

D75：BackPropagation

D76：優化器optimizers

D77：訓練神經網路的細節與技巧 - Validation and overfit

D78：訓練神經網路前的注意事項

D79：訓練神經網路的細節與技巧 - Learning rate effect

D80：[練習 Day] 優化器與學習率的組合與比較

D81：訓練神經網路的細節與技巧 - Regularization

D82：訓練神經網路的細節與技巧 - Dropout

D83：訓練神經網路的細節與技巧 - Batch normalization

D84：[練習 Day] 正規化/機移除/批次標準化的 組合與比較

D85：訓練神經網路的細節與技巧 - 使用 callbacks 函數做 earlystop

D86：訓練神經網路的細節與技巧 - 使用 callbacks 函數儲存 model

D87：訓練神經網路的細節與技巧 - 使用 callbacks 函數做 reduce learning rate

D88：訓練神經網路的細節與技巧 - 撰寫自己的 callbacks 函數

D89：訓練神經網路的細節與技巧 - 撰寫自己的 Loss function

D90：使用傳統電腦視覺與機器學習進行影像辨識

D91：[練習 Day] 使用傳統電腦視覺與機器學習進行影像辨識

D92：卷積神經網路 (Convolution Neural Network, CNN) 簡介

D93：卷積神經網路架構細節

D94：卷積神經網路 - 卷積(Convolution)層與參數調整

D95：卷積神經網路 - 池化(Pooling)層與參數調整

D96：Keras 中的 CNN layers

D97：使用 CNN 完成 CIFAR-10 資料集

D98：訓練卷積神經網路的細節與技巧 - 處理大量數據

D99：訓練卷積神經網路的細節與技巧 - 處理小量數據

D100：訓練卷積神經網路的細節與技巧 - 轉移學習 (Transfer learning)

D101~D103：Kaggle期末考-影像辨識

Bonus 進階補充：
